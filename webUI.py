import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Load mÃ´ hÃ¬nh Ä‘Ã£ fine-tune (local hoáº·c tá»« Hugging Face Hub)
model_name = "facebook/nllb-200-distilled-1.3B"  # hoáº·c 'your-username/nllb-finetuned-vi-th'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Mapping friendly names to NLLB language codes
language_map = {
    "Tiáº¿ng ThÃ¡i": "tha_Thai",
    "Tiáº¿ng Viá»‡t": "vie_Latn",
}

st.title("ğŸŒ Chatbot Dá»‹ch NgÃ´n Ngá»¯")
st.write("Sá»­ dá»¥ng mÃ´ hÃ¬nh NLLB-200 Ä‘Ã£ fine-tune Ä‘á»ƒ dá»‹ch giá»¯a ThÃ¡i, Viá»‡t")

with st.form("translate_form"):
    text = st.text_area("Nháº­p vÄƒn báº£n:")
    col1, col2 = st.columns(2)
    with col1:
        src_lang = st.selectbox("NgÃ´n ngá»¯ nguá»“n", list(language_map.keys()), index=0)
    with col2:
        tgt_lang = st.selectbox("NgÃ´n ngá»¯ Ä‘Ã­ch", list(language_map.keys()), index=1)

    submitted = st.form_submit_button("Dá»‹ch")

if submitted and text.strip() != "":
    with st.spinner("Äang dá»‹ch..."):
        src_code = language_map[src_lang]
        tgt_code = language_map[tgt_lang]

        inputs = tokenizer(text, return_tensors="pt")
        inputs["forced_bos_token_id"] = tokenizer.convert_tokens_to_ids(tgt_code)

        output_tokens = model.generate(**inputs, max_length=512)
        translated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)

        st.success("ğŸ‰ Dá»‹ch thÃ nh cÃ´ng!")
        st.text_area("Káº¿t quáº£ dá»‹ch:", translated_text, height=150)
